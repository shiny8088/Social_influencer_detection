{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1ab283-b652-4f31-9b2a-5115ff73026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99682327-2823-4467-8b1c-1216162bce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Influencer decision logic ===\n",
    "def is_influencer(followers, verified):\n",
    "    def convert_to_number(s):\n",
    "        s = s.lower().replace(\",\", \"\").strip()\n",
    "        s = re.sub(r'[^0-9.km]', '', s)\n",
    "        if 'm' in s:\n",
    "            return float(s.replace(\"m\", \"\")) * 1_000_000\n",
    "        elif 'k' in s:\n",
    "            return float(s.replace(\"k\", \"\")) * 1_000\n",
    "        try:\n",
    "            return float(s)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    followers_num = convert_to_number(followers)\n",
    "\n",
    "    if verified and followers_num > 10_000:\n",
    "        return \"✅ This person is likely an INFLUENCER.\"\n",
    "    elif not verified and followers_num > 10_000:\n",
    "        return \"✅ This person is likely an INFLUENCER.\"\n",
    "    else:\n",
    "        return \"❌ This person is NOT likely an influencer.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6c06f0-948b-4707-8e7b-452db98c0adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Profile: mostlysane\n",
      "✅ Verified: True\n",
      "👥 Followers: 8.8M followers\n",
      "➡️ Following: 5,390 following\n",
      "📝 Bio: N/A\n",
      "📌 3 post(s) found.\n",
      "\n",
      "🔍 Scraping comments for Post 1\n",
      "💬 adii.redkar\n",
      "💬 adii.redkar\n",
      "💬 AREY VARUN BHAIYA\n",
      "💬 10h36 likesReply\n",
      "💬 36 likes\n",
      "💬 Reply\n",
      "💬 prajakta__forever\n",
      "💬 prajakta__forever\n",
      "💬 Birthdayy countdown starts cutiee 👀🥳\n",
      "💬 11h5 likesReply\n",
      "💬 5 likes\n",
      "💬 Reply\n",
      "💬 _.mostlyprajakta._\n",
      "💬 _.mostlyprajakta._\n",
      "💬 🔥🙌🙌\n",
      "💬 11h1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 _chahathasija\n",
      "💬 _chahathasija\n",
      "💬 ❤️😍\n",
      "💬 11h1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 _ig.akash_\n",
      "💬 _ig.akash_\n",
      "💬 LoveLove 💕\n",
      "💬 11h1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 _.mostlyprajakta._\n",
      "💬 _.mostlyprajakta._\n",
      "💬 That freaking contagious smile of yours!!🥹🥹❤️\n",
      "💬 11h1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 mahima_chettri17\n",
      "💬 mahima_chettri17\n",
      "💬 😍❤️\n",
      "💬 7hReply\n",
      "💬 Reply\n",
      "💬 _parth_0102\n",
      "💬 _parth_0102\n",
      "💬 Areee varun bhaiya\n",
      "💬 11h10 likesReply\n",
      "See translation\n",
      "💬 10 likes\n",
      "💬 Reply\n",
      "💬 See translation\n",
      "💬 prajakta__forever\n",
      "💬 prajakta__forever\n",
      "💬 Youuu happpy ,, we happpyyy 😭\n",
      "💬 11h2 likesReply\n",
      "💬 2 likes\n",
      "💬 Reply\n",
      "💬 prajakta__forever\n",
      "💬 prajakta__forever\n",
      "💬 Are we getting some reference of this match in the upcoming book? 👀\n",
      "💬 11h6 likesReply\n",
      "💬 6 likes\n",
      "💬 Reply\n",
      "💬 prajuismine\n",
      "💬 prajuismine\n",
      "💬 Ayooo😍\n",
      "💬 11hReply\n",
      "💬 Reply\n",
      "💬 _.mostlyprajakta._\n",
      "💬 _.mostlyprajakta._\n",
      "💬 Monday motivation by P✅❤️\n",
      "💬 11h1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 prajuismine\n",
      "💬 prajuismine\n",
      "💬 Niceee!\n",
      "💬 11hReply\n",
      "💬 Reply\n",
      "💬 _.mostlyprajakta._\n",
      "💬 _.mostlyprajakta._\n",
      "💬 Ayyy cutiieeeee❤️\n",
      "💬 11h1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 sonaakshi.18\n",
      "💬 sonaakshi.18\n",
      "💬 ❤️❤️🔥\n",
      "💬 11h1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "🔍 Scraping comments for Post 2\n",
      "💬 theluxurypop\n",
      "💬 theluxurypop\n",
      "💬 😍\n",
      "💬 1dReply\n",
      "💬 Reply\n",
      "💬 prajakta_updates\n",
      "💬 prajakta_updates\n",
      "💬 Excited for Next Best seller Novel Author!!! 😌♥️🧿\n",
      "💬 2d16 likesReply\n",
      "💬 16 likes\n",
      "💬 Reply\n",
      "💬 __.stutiii._6\n",
      "💬 __.stutiii._6\n",
      "💬 😍❤️\n",
      "💬 2d2 likesReply\n",
      "💬 2 likes\n",
      "💬 Reply\n",
      "💬 pragya_singhi009\n",
      "💬 pragya_singhi009\n",
      "💬 Read your book for the 3rd time and it's really amazing !\n",
      "💬 2d3 likesReply\n",
      "💬 3 likes\n",
      "💬 Reply\n",
      "💬 prajaktakoli_.love\n",
      "💬 prajaktakoli_.love\n",
      "💬 Aaboo in Abu dhabi! ❤️\n",
      "💬 2d11 likesReply\n",
      "💬 11 likes\n",
      "💬 Reply\n",
      "💬 prajakta__forever\n",
      "💬 prajakta__forever\n",
      "💬 Your trip dump is always incomplete without minimum 1 food slide 😭\n",
      "💬 2d33 likesReply\n",
      "💬 33 likes\n",
      "💬 Reply\n",
      "💬 mriinaljyoti\n",
      "💬 mriinaljyoti\n",
      "💬 🧿🧿🧿\n",
      "💬 1d1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 _neha._.jain\n",
      "💬 _neha._.jain\n",
      "💬 At this point\n",
      "If this song is played I only remember you 👀\n",
      "💬 2d9 likesReply\n",
      "💬 9 likes\n",
      "💬 Reply\n",
      "💬 _nickiee.__\n",
      "💬 _nickiee.__\n",
      "💬 Delicious post🥹🤚🏻\n",
      "💬 2d3 likesReply\n",
      "💬 3 likes\n",
      "💬 Reply\n",
      "💬 mostlysane_mrinal\n",
      "💬 mostlysane_mrinal\n",
      "💬 Kindle ❤️🧿\n",
      "💬 2d4 likesReply\n",
      "💬 4 likes\n",
      "💬 Reply\n",
      "💬 prajuismine\n",
      "💬 prajuismine\n",
      "💬 👍🏼👍🏼👍🏼\n",
      "💬 2d2 likesReply\n",
      "💬 2 likes\n",
      "💬 Reply\n",
      "💬 manjiri.manjrekar\n",
      "💬 manjiri.manjrekar\n",
      "💬 Caption 👍\n",
      "💬 2d1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 abhivasu\n",
      "💬 abhivasu\n",
      "💬 Kindle version and cover from?\n",
      "💬 1d2 likesReply\n",
      "💬 2 likes\n",
      "💬 Reply\n",
      "💬 prajuismine\n",
      "💬 prajuismine\n",
      "💬 Such cool life you're living in!!\n",
      "💬 2d4 likesReply\n",
      "💬 4 likes\n",
      "💬 Reply\n",
      "💬 rohit_zone_0\n",
      "💬 rohit_zone_0\n",
      "💬 Bhutukkai bhaye ma @mostlysane 🥹♥️\n",
      "💬 2d2 likesReply\n",
      "💬 2 likes\n",
      "💬 Reply\n",
      "🔍 Scraping comments for Post 3\n",
      "💬 rammyahh\n",
      "💬 rammyahh\n",
      "💬 Hey cutie! 😍❤️\n",
      "💬 1w4 likesReply\n",
      "💬 4 likes\n",
      "💬 Reply\n",
      "💬 not.jd7\n",
      "💬 not.jd7\n",
      "💬 🔥🔥\n",
      "💬 1w1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 _chahathasija\n",
      "💬 _chahathasija\n",
      "💬 Yay❤️\n",
      "💬 1w1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 pri_ya.barman\n",
      "💬 pri_ya.barman\n",
      "💬 👏🔥\n",
      "💬 1w1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 mr__azyn\n",
      "💬 mr__azyn\n",
      "💬 ❤️❤️\n",
      "💬 1w3 likesReply\n",
      "💬 3 likes\n",
      "💬 Reply\n",
      "💬 rituu_sharma03\n",
      "💬 rituu_sharma03\n",
      "💬 ❤️\n",
      "💬 1w1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 cinemagicqueens\n",
      "💬 cinemagicqueens\n",
      "💬 💖🥀👀\n",
      "💬 1w4 likesReply\n",
      "💬 4 likes\n",
      "💬 Reply\n",
      "💬 _ig.akash_\n",
      "💬 _ig.akash_\n",
      "💬 LoveLove 💕\n",
      "💬 1w3 likesReply\n",
      "💬 3 likes\n",
      "💬 Reply\n",
      "💬 aishababy7168\n",
      "💬 aishababy7168\n",
      "💬 😍😍\n",
      "💬 1w3 likesReply\n",
      "💬 3 likes\n",
      "💬 Reply\n",
      "💬 swati_sandaliya\n",
      "💬 swati_sandaliya\n",
      "💬 🔥🔥\n",
      "💬 1w1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 justt_aishani\n",
      "💬 justt_aishani\n",
      "💬 LOVE U ❤️\n",
      "💬 1w3 likesReply\n",
      "💬 3 likes\n",
      "💬 Reply\n",
      "💬 parijit_.532\n",
      "💬 parijit_.532\n",
      "💬 ❤️🙌\n",
      "💬 1w4 likesReply\n",
      "💬 4 likes\n",
      "💬 Reply\n",
      "💬 amitkheni\n",
      "💬 amitkheni\n",
      "💬 ❤️❤️\n",
      "💬 1w4 likesReply\n",
      "💬 4 likes\n",
      "💬 Reply\n",
      "💬 _manaswini.kumar_\n",
      "💬 _manaswini.kumar_\n",
      "💬 ❤️\n",
      "💬 1w1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "💬 soumita.biswas.965928\n",
      "💬 soumita.biswas.965928\n",
      "💬 Cutie 🥰🥰\n",
      "💬 1w1 likeReply\n",
      "💬 1 like\n",
      "💬 Reply\n",
      "\n",
      "✅ Comments saved to: comments_postwise_mostlysane.csv\n",
      "\n",
      "✅ Sentiment Model Accuracy: 0.93\n",
      "\n",
      "📊 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       100\n",
      "           1       0.97      0.89      0.93       100\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.93      0.93      0.93       200\n",
      "weighted avg       0.93      0.93      0.93       200\n",
      "\n",
      "\n",
      "📊 Sentiment Distribution:\n",
      " Predicted_Sentiment\n",
      "0    20\n",
      "1     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🧠 Final Decision:\n",
      "✅ This person is likely an INFLUENCER.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Settings ===\n",
    "USERNAME = \"maggie_888880\"\n",
    "PASSWORD = \"Miss_maggie8088\"\n",
    "TARGET_USER = \"mostlysane\"  # Replace with actual username\n",
    "POST_COUNT = 3\n",
    "comments_data = []\n",
    "\n",
    "async def fetch_instagram_data():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "\n",
    "        # Login\n",
    "        await page.goto(\"https://www.instagram.com/accounts/login/\")\n",
    "        await page.wait_for_timeout(5000)\n",
    "        await page.fill(\"input[name='username']\", USERNAME)\n",
    "        await page.fill(\"input[name='password']\", PASSWORD)\n",
    "        await page.click(\"button[type='submit']\")\n",
    "        await page.wait_for_timeout(7000)\n",
    "\n",
    "        for button_text in [\"Not Now\", \"Save Info\", \"Turn on Notifications\"]:\n",
    "            try:\n",
    "                btn = await page.wait_for_selector(f'//button[contains(text(), \"{button_text}\")]', timeout=5000)\n",
    "                await btn.click()\n",
    "                await page.wait_for_timeout(2000)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        await page.goto(f\"https://www.instagram.com/{TARGET_USER}/\")\n",
    "        await page.wait_for_timeout(5000)\n",
    "\n",
    "        # Check if account is private\n",
    "        try:\n",
    "            private_text_elem = await page.query_selector(\"h2\")\n",
    "            private_text = await private_text_elem.inner_text() if private_text_elem else \"\"\n",
    "            if \"This Account is Private\" in private_text or \"This Account is Private.\" in private_text:\n",
    "                print(f\"❌ The account @{TARGET_USER} is PRIVATE.\")\n",
    "                await browser.close()\n",
    "                return {\n",
    "                    \"df\": pd.DataFrame(),\n",
    "                    \"csv_path\": None,\n",
    "                    \"followers\": \"0\",\n",
    "                    \"following\": \"0\",\n",
    "                    \"verified\": False,\n",
    "                    \"is_private\": True\n",
    "                }\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Extract profile info\n",
    "        try:\n",
    "            stats = await page.query_selector_all(\"header section ul li\")\n",
    "            followers, following = \"N/A\", \"N/A\"\n",
    "            if len(stats) >= 3:\n",
    "                followers = await stats[1].inner_text()\n",
    "                following = await stats[2].inner_text()\n",
    "            is_verified = await page.query_selector(\"header svg[aria-label='Verified']\") is not None\n",
    "            bio_elem = await page.query_selector(\"header section div.-vDIg > span\")\n",
    "            about = await bio_elem.inner_text() if bio_elem else \"N/A\"\n",
    "\n",
    "            print(f\"\\n📄 Profile: {TARGET_USER}\")\n",
    "            print(f\"✅ Verified: {is_verified}\")\n",
    "            print(f\"👥 Followers: {followers}\")\n",
    "            print(f\"➡️ Following: {following}\")\n",
    "            print(f\"📝 Bio: {about}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"❌ Error extracting profile data:\", str(e))\n",
    "            followers, following, is_verified = \"0\", \"0\", False\n",
    "\n",
    "        # Scroll to load posts\n",
    "        await page.mouse.wheel(0, 3000)\n",
    "        await page.wait_for_timeout(3000)\n",
    "\n",
    "        anchors = await page.query_selector_all(\"a\")\n",
    "        post_links = []\n",
    "        for a in anchors:\n",
    "            href = await a.get_attribute(\"href\")\n",
    "            if href and \"/p/\" in href:\n",
    "                full_url = \"https://www.instagram.com\" + href\n",
    "                if full_url not in post_links:\n",
    "                    post_links.append(full_url)\n",
    "            if len(post_links) >= POST_COUNT:\n",
    "                break\n",
    "\n",
    "        print(f\"📌 {len(post_links)} post(s) found.\\n\")\n",
    "\n",
    "        for i, post_url in enumerate(post_links):\n",
    "            post_num = i + 1\n",
    "            print(f\"🔍 Scraping comments for Post {post_num}\")\n",
    "            await page.goto(post_url)\n",
    "            await page.wait_for_timeout(5000)\n",
    "\n",
    "            for _ in range(10):\n",
    "                try:\n",
    "                    more_btn = await page.query_selector('//button[contains(text(), \"Load more comments\")]')\n",
    "                    if more_btn:\n",
    "                        await more_btn.click()\n",
    "                        await page.wait_for_timeout(2000)\n",
    "                    else:\n",
    "                        break\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            for _ in range(10):\n",
    "                await page.mouse.wheel(0, 1500)\n",
    "                await page.wait_for_timeout(1000)\n",
    "\n",
    "            try:\n",
    "                comment_blocks = await page.query_selector_all(\"ul ul div li span\")\n",
    "                for block in comment_blocks:\n",
    "                    try:\n",
    "                        comment = await block.inner_text()\n",
    "                        if comment.strip():\n",
    "                            comments_data.append({\n",
    "                                \"Post Number\": post_num,\n",
    "                                \"Comment\": comment.strip()\n",
    "                            })\n",
    "                            print(f\"💬 {comment.strip()}\")\n",
    "                    except:\n",
    "                        continue\n",
    "            except:\n",
    "                print(\"⚠️ No comments found on this post.\")\n",
    "                continue\n",
    "\n",
    "        await browser.close()\n",
    "        df = pd.DataFrame(comments_data)\n",
    "        csv_path = f\"comments_postwise_{TARGET_USER}.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"\\n✅ Comments saved to: {csv_path}\")\n",
    "\n",
    "        return {\n",
    "            \"df\": df,\n",
    "            \"csv_path\": csv_path,\n",
    "            \"followers\": followers,\n",
    "            \"following\": following,\n",
    "            \"verified\": is_verified,\n",
    "            \"is_private\": False\n",
    "        }\n",
    "\n",
    "def clean_comment(comment):\n",
    "    comment = re.sub(r'[^\\x00-\\x7F]+', '', comment)\n",
    "    if re.match(r'^[A-Za-z0-9_.]+$', comment):\n",
    "        return ''\n",
    "    comment = re.sub(r'\\b(?:Reply|likes?|See translation)\\b', '', comment, flags=re.IGNORECASE)\n",
    "    comment = re.sub(r'\\s+', ' ', comment).strip()\n",
    "    if re.search(r'\\d', comment):\n",
    "        return ''\n",
    "    return comment\n",
    "\n",
    "async def main():\n",
    "    result = await fetch_instagram_data()\n",
    "\n",
    "    if result.get(\"is_private\", False):\n",
    "        print(f\"\\n🧠 Final Decision:\\n❌ The account @{TARGET_USER} is PRIVATE and NOT an influencer.\")\n",
    "        return  # Stop further processing if private\n",
    "\n",
    "    csv_path = result['csv_path']\n",
    "    followers = result['followers']\n",
    "    verified = result['verified']\n",
    "\n",
    "    # Check if CSV path is valid and file exists\n",
    "    if not csv_path or not os.path.exists(csv_path):\n",
    "        print(f\"\\n⚠️ Comments CSV not found, stopping analysis.\")\n",
    "        print(f\"\\n🧠 Final Decision:\\n❌ The account @{TARGET_USER} is NOT an influencer.\")\n",
    "        return\n",
    "\n",
    "    # Check if CSV file is empty\n",
    "    if os.path.getsize(csv_path) == 0:\n",
    "        print(f\"\\n⚠️ Comments CSV is empty. No comments found.\")\n",
    "        print(f\"\\n🧠 Final Decision:\\n❌ The account @{TARGET_USER} is NOT an influencer.\")\n",
    "        return\n",
    "\n",
    "    # Load CSV safely with try-except for empty or malformed files\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"\\n⚠️ Comments CSV is empty or malformed.\")\n",
    "        print(f\"\\n🧠 Final Decision:\\n❌ The account @{TARGET_USER} is NOT an influencer.\")\n",
    "        return\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"\\n⚠️ Comments CSV has no data rows.\")\n",
    "        print(f\"\\n🧠 Final Decision:\\n❌ The account @{TARGET_USER} is NOT an influencer.\")\n",
    "        return\n",
    "\n",
    "    comments = df['Comment'].astype(str)\n",
    "\n",
    "    cleaned_comments = comments.apply(clean_comment)\n",
    "    cleaned_comments = cleaned_comments[cleaned_comments != '']\n",
    "    cleaned_df = pd.DataFrame({'Comment': cleaned_comments})\n",
    "    cleaned_df.to_csv(\"cleaned_comments_no_numbers.csv\", index=False)\n",
    "\n",
    "    # === Sentiment analysis (for display only) ===\n",
    "    try:\n",
    "        labeled_df = pd.read_csv(\"instagram_sentiment_dataset.csv\")  # Must exist\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Sentiment dataset missing or error reading: {e}\")\n",
    "        print(f\"\\n🧠 Final Decision:\\n{is_influencer(followers, verified)}\")\n",
    "        return\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        labeled_df['Comment'], labeled_df['Label'], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n✅ Sentiment Model Accuracy: {accuracy:.2f}\")\n",
    "    print(\"\\n📊 Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    real_comments = cleaned_df['Comment'].dropna()\n",
    "    predicted_sentiments = model.predict(real_comments)\n",
    "    cleaned_df['Predicted_Sentiment'] = predicted_sentiments\n",
    "    cleaned_df.to_csv(\"cleaned_comments_with_predictions.csv\", index=False)\n",
    "\n",
    "    sentiment_counts = cleaned_df['Predicted_Sentiment'].value_counts()\n",
    "    print(\"\\n📊 Sentiment Distribution:\\n\", sentiment_counts)\n",
    "\n",
    "    # === Final influencer decision ===\n",
    "    print(f\"\\n🧠 Final Decision:\\n{is_influencer(followers, verified)}\")\n",
    "\n",
    "# Run in Jupyter or interactive environment:\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
