{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1ab283-b652-4f31-9b2a-5115ff73026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99682327-2823-4467-8b1c-1216162bce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Influencer decision logic ===\n",
    "def is_influencer(followers, verified):\n",
    "    def convert_to_number(s):\n",
    "        s = s.lower().replace(\",\", \"\").strip()\n",
    "        s = re.sub(r'[^0-9.km]', '', s)\n",
    "        if 'm' in s:\n",
    "            return float(s.replace(\"m\", \"\")) * 1_000_000\n",
    "        elif 'k' in s:\n",
    "            return float(s.replace(\"k\", \"\")) * 1_000\n",
    "        try:\n",
    "            return float(s)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    followers_num = convert_to_number(followers)\n",
    "\n",
    "    if verified and followers_num > 10_000:\n",
    "        return \"‚úÖ This person is likely an INFLUENCER.\"\n",
    "    elif not verified and followers_num > 10_000:\n",
    "        return \"‚úÖ This person is likely an INFLUENCER.\"\n",
    "    else:\n",
    "        return \"‚ùå This person is NOT likely an influencer.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6c06f0-948b-4707-8e7b-452db98c0adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Profile: mostlysane\n",
      "‚úÖ Verified: True\n",
      "üë• Followers: 8.8M followers\n",
      "‚û°Ô∏è Following: 5,390 following\n",
      "üìù Bio: N/A\n",
      "üìå 3 post(s) found.\n",
      "\n",
      "üîç Scraping comments for Post 1\n",
      "üí¨ adii.redkar\n",
      "üí¨ adii.redkar\n",
      "üí¨ AREY VARUN BHAIYA\n",
      "üí¨ 10h36 likesReply\n",
      "üí¨ 36 likes\n",
      "üí¨ Reply\n",
      "üí¨ prajakta__forever\n",
      "üí¨ prajakta__forever\n",
      "üí¨ Birthdayy countdown starts cutiee üëÄü•≥\n",
      "üí¨ 11h5 likesReply\n",
      "üí¨ 5 likes\n",
      "üí¨ Reply\n",
      "üí¨ _.mostlyprajakta._\n",
      "üí¨ _.mostlyprajakta._\n",
      "üí¨ üî•üôåüôå\n",
      "üí¨ 11h1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ _chahathasija\n",
      "üí¨ _chahathasija\n",
      "üí¨ ‚ù§Ô∏èüòç\n",
      "üí¨ 11h1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ _ig.akash_\n",
      "üí¨ _ig.akash_\n",
      "üí¨ LoveLove üíï\n",
      "üí¨ 11h1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ _.mostlyprajakta._\n",
      "üí¨ _.mostlyprajakta._\n",
      "üí¨ That freaking contagious smile of yours!!ü•πü•π‚ù§Ô∏è\n",
      "üí¨ 11h1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ mahima_chettri17\n",
      "üí¨ mahima_chettri17\n",
      "üí¨ üòç‚ù§Ô∏è\n",
      "üí¨ 7hReply\n",
      "üí¨ Reply\n",
      "üí¨ _parth_0102\n",
      "üí¨ _parth_0102\n",
      "üí¨ Areee varun bhaiya\n",
      "üí¨ 11h10 likesReply\n",
      "See translation\n",
      "üí¨ 10 likes\n",
      "üí¨ Reply\n",
      "üí¨ See translation\n",
      "üí¨ prajakta__forever\n",
      "üí¨ prajakta__forever\n",
      "üí¨ Youuu happpy ,, we happpyyy üò≠\n",
      "üí¨ 11h2 likesReply\n",
      "üí¨ 2 likes\n",
      "üí¨ Reply\n",
      "üí¨ prajakta__forever\n",
      "üí¨ prajakta__forever\n",
      "üí¨ Are we getting some reference of this match in the upcoming book? üëÄ\n",
      "üí¨ 11h6 likesReply\n",
      "üí¨ 6 likes\n",
      "üí¨ Reply\n",
      "üí¨ prajuismine\n",
      "üí¨ prajuismine\n",
      "üí¨ Ayoooüòç\n",
      "üí¨ 11hReply\n",
      "üí¨ Reply\n",
      "üí¨ _.mostlyprajakta._\n",
      "üí¨ _.mostlyprajakta._\n",
      "üí¨ Monday motivation by P‚úÖ‚ù§Ô∏è\n",
      "üí¨ 11h1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ prajuismine\n",
      "üí¨ prajuismine\n",
      "üí¨ Niceee!\n",
      "üí¨ 11hReply\n",
      "üí¨ Reply\n",
      "üí¨ _.mostlyprajakta._\n",
      "üí¨ _.mostlyprajakta._\n",
      "üí¨ Ayyy cutiieeeee‚ù§Ô∏è\n",
      "üí¨ 11h1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ sonaakshi.18\n",
      "üí¨ sonaakshi.18\n",
      "üí¨ ‚ù§Ô∏è‚ù§Ô∏èüî•\n",
      "üí¨ 11h1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üîç Scraping comments for Post 2\n",
      "üí¨ theluxurypop\n",
      "üí¨ theluxurypop\n",
      "üí¨ üòç\n",
      "üí¨ 1dReply\n",
      "üí¨ Reply\n",
      "üí¨ prajakta_updates\n",
      "üí¨ prajakta_updates\n",
      "üí¨ Excited for Next Best seller Novel Author!!! üòå‚ô•Ô∏èüßø\n",
      "üí¨ 2d16 likesReply\n",
      "üí¨ 16 likes\n",
      "üí¨ Reply\n",
      "üí¨ __.stutiii._6\n",
      "üí¨ __.stutiii._6\n",
      "üí¨ üòç‚ù§Ô∏è\n",
      "üí¨ 2d2 likesReply\n",
      "üí¨ 2 likes\n",
      "üí¨ Reply\n",
      "üí¨ pragya_singhi009\n",
      "üí¨ pragya_singhi009\n",
      "üí¨ Read your book for the 3rd time and it's really amazing !\n",
      "üí¨ 2d3 likesReply\n",
      "üí¨ 3 likes\n",
      "üí¨ Reply\n",
      "üí¨ prajaktakoli_.love\n",
      "üí¨ prajaktakoli_.love\n",
      "üí¨ Aaboo in Abu dhabi! ‚ù§Ô∏è\n",
      "üí¨ 2d11 likesReply\n",
      "üí¨ 11 likes\n",
      "üí¨ Reply\n",
      "üí¨ prajakta__forever\n",
      "üí¨ prajakta__forever\n",
      "üí¨ Your trip dump is always incomplete without minimum 1 food slide üò≠\n",
      "üí¨ 2d33 likesReply\n",
      "üí¨ 33 likes\n",
      "üí¨ Reply\n",
      "üí¨ mriinaljyoti\n",
      "üí¨ mriinaljyoti\n",
      "üí¨ üßøüßøüßø\n",
      "üí¨ 1d1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ _neha._.jain\n",
      "üí¨ _neha._.jain\n",
      "üí¨ At this point\n",
      "If this song is played I only remember you üëÄ\n",
      "üí¨ 2d9 likesReply\n",
      "üí¨ 9 likes\n",
      "üí¨ Reply\n",
      "üí¨ _nickiee.__\n",
      "üí¨ _nickiee.__\n",
      "üí¨ Delicious postü•πü§öüèª\n",
      "üí¨ 2d3 likesReply\n",
      "üí¨ 3 likes\n",
      "üí¨ Reply\n",
      "üí¨ mostlysane_mrinal\n",
      "üí¨ mostlysane_mrinal\n",
      "üí¨ Kindle ‚ù§Ô∏èüßø\n",
      "üí¨ 2d4 likesReply\n",
      "üí¨ 4 likes\n",
      "üí¨ Reply\n",
      "üí¨ prajuismine\n",
      "üí¨ prajuismine\n",
      "üí¨ üëçüèºüëçüèºüëçüèº\n",
      "üí¨ 2d2 likesReply\n",
      "üí¨ 2 likes\n",
      "üí¨ Reply\n",
      "üí¨ manjiri.manjrekar\n",
      "üí¨ manjiri.manjrekar\n",
      "üí¨ Caption üëç\n",
      "üí¨ 2d1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ abhivasu\n",
      "üí¨ abhivasu\n",
      "üí¨ Kindle version and cover from?\n",
      "üí¨ 1d2 likesReply\n",
      "üí¨ 2 likes\n",
      "üí¨ Reply\n",
      "üí¨ prajuismine\n",
      "üí¨ prajuismine\n",
      "üí¨ Such cool life you're living in!!\n",
      "üí¨ 2d4 likesReply\n",
      "üí¨ 4 likes\n",
      "üí¨ Reply\n",
      "üí¨ rohit_zone_0\n",
      "üí¨ rohit_zone_0\n",
      "üí¨ Bhutukkai bhaye ma @mostlysane ü•π‚ô•Ô∏è\n",
      "üí¨ 2d2 likesReply\n",
      "üí¨ 2 likes\n",
      "üí¨ Reply\n",
      "üîç Scraping comments for Post 3\n",
      "üí¨ rammyahh\n",
      "üí¨ rammyahh\n",
      "üí¨ Hey cutie! üòç‚ù§Ô∏è\n",
      "üí¨ 1w4 likesReply\n",
      "üí¨ 4 likes\n",
      "üí¨ Reply\n",
      "üí¨ not.jd7\n",
      "üí¨ not.jd7\n",
      "üí¨ üî•üî•\n",
      "üí¨ 1w1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ _chahathasija\n",
      "üí¨ _chahathasija\n",
      "üí¨ Yay‚ù§Ô∏è\n",
      "üí¨ 1w1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ pri_ya.barman\n",
      "üí¨ pri_ya.barman\n",
      "üí¨ üëèüî•\n",
      "üí¨ 1w1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ mr__azyn\n",
      "üí¨ mr__azyn\n",
      "üí¨ ‚ù§Ô∏è‚ù§Ô∏è\n",
      "üí¨ 1w3 likesReply\n",
      "üí¨ 3 likes\n",
      "üí¨ Reply\n",
      "üí¨ rituu_sharma03\n",
      "üí¨ rituu_sharma03\n",
      "üí¨ ‚ù§Ô∏è\n",
      "üí¨ 1w1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ cinemagicqueens\n",
      "üí¨ cinemagicqueens\n",
      "üí¨ üíñü•ÄüëÄ\n",
      "üí¨ 1w4 likesReply\n",
      "üí¨ 4 likes\n",
      "üí¨ Reply\n",
      "üí¨ _ig.akash_\n",
      "üí¨ _ig.akash_\n",
      "üí¨ LoveLove üíï\n",
      "üí¨ 1w3 likesReply\n",
      "üí¨ 3 likes\n",
      "üí¨ Reply\n",
      "üí¨ aishababy7168\n",
      "üí¨ aishababy7168\n",
      "üí¨ üòçüòç\n",
      "üí¨ 1w3 likesReply\n",
      "üí¨ 3 likes\n",
      "üí¨ Reply\n",
      "üí¨ swati_sandaliya\n",
      "üí¨ swati_sandaliya\n",
      "üí¨ üî•üî•\n",
      "üí¨ 1w1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ justt_aishani\n",
      "üí¨ justt_aishani\n",
      "üí¨ LOVE U ‚ù§Ô∏è\n",
      "üí¨ 1w3 likesReply\n",
      "üí¨ 3 likes\n",
      "üí¨ Reply\n",
      "üí¨ parijit_.532\n",
      "üí¨ parijit_.532\n",
      "üí¨ ‚ù§Ô∏èüôå\n",
      "üí¨ 1w4 likesReply\n",
      "üí¨ 4 likes\n",
      "üí¨ Reply\n",
      "üí¨ amitkheni\n",
      "üí¨ amitkheni\n",
      "üí¨ ‚ù§Ô∏è‚ù§Ô∏è\n",
      "üí¨ 1w4 likesReply\n",
      "üí¨ 4 likes\n",
      "üí¨ Reply\n",
      "üí¨ _manaswini.kumar_\n",
      "üí¨ _manaswini.kumar_\n",
      "üí¨ ‚ù§Ô∏è\n",
      "üí¨ 1w1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "üí¨ soumita.biswas.965928\n",
      "üí¨ soumita.biswas.965928\n",
      "üí¨ Cutie ü•∞ü•∞\n",
      "üí¨ 1w1 likeReply\n",
      "üí¨ 1 like\n",
      "üí¨ Reply\n",
      "\n",
      "‚úÖ Comments saved to: comments_postwise_mostlysane.csv\n",
      "\n",
      "‚úÖ Sentiment Model Accuracy: 0.93\n",
      "\n",
      "üìä Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       100\n",
      "           1       0.97      0.89      0.93       100\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.93      0.93      0.93       200\n",
      "weighted avg       0.93      0.93      0.93       200\n",
      "\n",
      "\n",
      "üìä Sentiment Distribution:\n",
      " Predicted_Sentiment\n",
      "0    20\n",
      "1     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üß† Final Decision:\n",
      "‚úÖ This person is likely an INFLUENCER.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Settings ===\n",
    "USERNAME = \"maggie_888880\"\n",
    "PASSWORD = \"Miss_maggie8088\"\n",
    "TARGET_USER = \"mostlysane\"  # Replace with actual username\n",
    "POST_COUNT = 3\n",
    "comments_data = []\n",
    "\n",
    "async def fetch_instagram_data():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "\n",
    "        # Login\n",
    "        await page.goto(\"https://www.instagram.com/accounts/login/\")\n",
    "        await page.wait_for_timeout(5000)\n",
    "        await page.fill(\"input[name='username']\", USERNAME)\n",
    "        await page.fill(\"input[name='password']\", PASSWORD)\n",
    "        await page.click(\"button[type='submit']\")\n",
    "        await page.wait_for_timeout(7000)\n",
    "\n",
    "        for button_text in [\"Not Now\", \"Save Info\", \"Turn on Notifications\"]:\n",
    "            try:\n",
    "                btn = await page.wait_for_selector(f'//button[contains(text(), \"{button_text}\")]', timeout=5000)\n",
    "                await btn.click()\n",
    "                await page.wait_for_timeout(2000)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        await page.goto(f\"https://www.instagram.com/{TARGET_USER}/\")\n",
    "        await page.wait_for_timeout(5000)\n",
    "\n",
    "        # Check if account is private\n",
    "        try:\n",
    "            private_text_elem = await page.query_selector(\"h2\")\n",
    "            private_text = await private_text_elem.inner_text() if private_text_elem else \"\"\n",
    "            if \"This Account is Private\" in private_text or \"This Account is Private.\" in private_text:\n",
    "                print(f\"‚ùå The account @{TARGET_USER} is PRIVATE.\")\n",
    "                await browser.close()\n",
    "                return {\n",
    "                    \"df\": pd.DataFrame(),\n",
    "                    \"csv_path\": None,\n",
    "                    \"followers\": \"0\",\n",
    "                    \"following\": \"0\",\n",
    "                    \"verified\": False,\n",
    "                    \"is_private\": True\n",
    "                }\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Extract profile info\n",
    "        try:\n",
    "            stats = await page.query_selector_all(\"header section ul li\")\n",
    "            followers, following = \"N/A\", \"N/A\"\n",
    "            if len(stats) >= 3:\n",
    "                followers = await stats[1].inner_text()\n",
    "                following = await stats[2].inner_text()\n",
    "            is_verified = await page.query_selector(\"header svg[aria-label='Verified']\") is not None\n",
    "            bio_elem = await page.query_selector(\"header section div.-vDIg > span\")\n",
    "            about = await bio_elem.inner_text() if bio_elem else \"N/A\"\n",
    "\n",
    "            print(f\"\\nüìÑ Profile: {TARGET_USER}\")\n",
    "            print(f\"‚úÖ Verified: {is_verified}\")\n",
    "            print(f\"üë• Followers: {followers}\")\n",
    "            print(f\"‚û°Ô∏è Following: {following}\")\n",
    "            print(f\"üìù Bio: {about}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Error extracting profile data:\", str(e))\n",
    "            followers, following, is_verified = \"0\", \"0\", False\n",
    "\n",
    "        # Scroll to load posts\n",
    "        await page.mouse.wheel(0, 3000)\n",
    "        await page.wait_for_timeout(3000)\n",
    "\n",
    "        anchors = await page.query_selector_all(\"a\")\n",
    "        post_links = []\n",
    "        for a in anchors:\n",
    "            href = await a.get_attribute(\"href\")\n",
    "            if href and \"/p/\" in href:\n",
    "                full_url = \"https://www.instagram.com\" + href\n",
    "                if full_url not in post_links:\n",
    "                    post_links.append(full_url)\n",
    "            if len(post_links) >= POST_COUNT:\n",
    "                break\n",
    "\n",
    "        print(f\"üìå {len(post_links)} post(s) found.\\n\")\n",
    "\n",
    "        for i, post_url in enumerate(post_links):\n",
    "            post_num = i + 1\n",
    "            print(f\"üîç Scraping comments for Post {post_num}\")\n",
    "            await page.goto(post_url)\n",
    "            await page.wait_for_timeout(5000)\n",
    "\n",
    "            for _ in range(10):\n",
    "                try:\n",
    "                    more_btn = await page.query_selector('//button[contains(text(), \"Load more comments\")]')\n",
    "                    if more_btn:\n",
    "                        await more_btn.click()\n",
    "                        await page.wait_for_timeout(2000)\n",
    "                    else:\n",
    "                        break\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            for _ in range(10):\n",
    "                await page.mouse.wheel(0, 1500)\n",
    "                await page.wait_for_timeout(1000)\n",
    "\n",
    "            try:\n",
    "                comment_blocks = await page.query_selector_all(\"ul ul div li span\")\n",
    "                for block in comment_blocks:\n",
    "                    try:\n",
    "                        comment = await block.inner_text()\n",
    "                        if comment.strip():\n",
    "                            comments_data.append({\n",
    "                                \"Post Number\": post_num,\n",
    "                                \"Comment\": comment.strip()\n",
    "                            })\n",
    "                            print(f\"üí¨ {comment.strip()}\")\n",
    "                    except:\n",
    "                        continue\n",
    "            except:\n",
    "                print(\"‚ö†Ô∏è No comments found on this post.\")\n",
    "                continue\n",
    "\n",
    "        await browser.close()\n",
    "        df = pd.DataFrame(comments_data)\n",
    "        csv_path = f\"comments_postwise_{TARGET_USER}.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"\\n‚úÖ Comments saved to: {csv_path}\")\n",
    "\n",
    "        return {\n",
    "            \"df\": df,\n",
    "            \"csv_path\": csv_path,\n",
    "            \"followers\": followers,\n",
    "            \"following\": following,\n",
    "            \"verified\": is_verified,\n",
    "            \"is_private\": False\n",
    "        }\n",
    "\n",
    "def clean_comment(comment):\n",
    "    comment = re.sub(r'[^\\x00-\\x7F]+', '', comment)\n",
    "    if re.match(r'^[A-Za-z0-9_.]+$', comment):\n",
    "        return ''\n",
    "    comment = re.sub(r'\\b(?:Reply|likes?|See translation)\\b', '', comment, flags=re.IGNORECASE)\n",
    "    comment = re.sub(r'\\s+', ' ', comment).strip()\n",
    "    if re.search(r'\\d', comment):\n",
    "        return ''\n",
    "    return comment\n",
    "\n",
    "async def main():\n",
    "    result = await fetch_instagram_data()\n",
    "\n",
    "    if result.get(\"is_private\", False):\n",
    "        print(f\"\\nüß† Final Decision:\\n‚ùå The account @{TARGET_USER} is PRIVATE and NOT an influencer.\")\n",
    "        return  # Stop further processing if private\n",
    "\n",
    "    csv_path = result['csv_path']\n",
    "    followers = result['followers']\n",
    "    verified = result['verified']\n",
    "\n",
    "    # Check if CSV path is valid and file exists\n",
    "    if not csv_path or not os.path.exists(csv_path):\n",
    "        print(f\"\\n‚ö†Ô∏è Comments CSV not found, stopping analysis.\")\n",
    "        print(f\"\\nüß† Final Decision:\\n‚ùå The account @{TARGET_USER} is NOT an influencer.\")\n",
    "        return\n",
    "\n",
    "    # Check if CSV file is empty\n",
    "    if os.path.getsize(csv_path) == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è Comments CSV is empty. No comments found.\")\n",
    "        print(f\"\\nüß† Final Decision:\\n‚ùå The account @{TARGET_USER} is NOT an influencer.\")\n",
    "        return\n",
    "\n",
    "    # Load CSV safely with try-except for empty or malformed files\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"\\n‚ö†Ô∏è Comments CSV is empty or malformed.\")\n",
    "        print(f\"\\nüß† Final Decision:\\n‚ùå The account @{TARGET_USER} is NOT an influencer.\")\n",
    "        return\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"\\n‚ö†Ô∏è Comments CSV has no data rows.\")\n",
    "        print(f\"\\nüß† Final Decision:\\n‚ùå The account @{TARGET_USER} is NOT an influencer.\")\n",
    "        return\n",
    "\n",
    "    comments = df['Comment'].astype(str)\n",
    "\n",
    "    cleaned_comments = comments.apply(clean_comment)\n",
    "    cleaned_comments = cleaned_comments[cleaned_comments != '']\n",
    "    cleaned_df = pd.DataFrame({'Comment': cleaned_comments})\n",
    "    cleaned_df.to_csv(\"cleaned_comments_no_numbers.csv\", index=False)\n",
    "\n",
    "    # === Sentiment analysis (for display only) ===\n",
    "    try:\n",
    "        labeled_df = pd.read_csv(\"instagram_sentiment_dataset.csv\")  # Must exist\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Sentiment dataset missing or error reading: {e}\")\n",
    "        print(f\"\\nüß† Final Decision:\\n{is_influencer(followers, verified)}\")\n",
    "        return\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        labeled_df['Comment'], labeled_df['Label'], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n‚úÖ Sentiment Model Accuracy: {accuracy:.2f}\")\n",
    "    print(\"\\nüìä Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    real_comments = cleaned_df['Comment'].dropna()\n",
    "    predicted_sentiments = model.predict(real_comments)\n",
    "    cleaned_df['Predicted_Sentiment'] = predicted_sentiments\n",
    "    cleaned_df.to_csv(\"cleaned_comments_with_predictions.csv\", index=False)\n",
    "\n",
    "    sentiment_counts = cleaned_df['Predicted_Sentiment'].value_counts()\n",
    "    print(\"\\nüìä Sentiment Distribution:\\n\", sentiment_counts)\n",
    "\n",
    "    # === Final influencer decision ===\n",
    "    print(f\"\\nüß† Final Decision:\\n{is_influencer(followers, verified)}\")\n",
    "\n",
    "# Run in Jupyter or interactive environment:\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
